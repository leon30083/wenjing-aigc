=================head===============
http://127.0.0.1:8188/object_info/FaceDetailer=================post===============
=================head===============
=================body===============
{"FaceDetailer": {"input": {"required": {"image": ["IMAGE"], "model": ["MODEL", {"tooltip": "If the `ImpactDummyInput` is connected to the model, the inference stage is skipped."}], "clip": ["CLIP"], "vae": ["VAE"], "guide_size": ["FLOAT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "guide_size_for": ["BOOLEAN", {"default": true, "label_on": "bbox", "label_off": "crop_region"}], "max_size": ["FLOAT", {"default": 1024, "min": 64, "max": 16384, "step": 8}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "denoise": ["FLOAT", {"default": 0.5, "min": 0.0001, "max": 1.0, "step": 0.01}], "feather": ["INT", {"default": 5, "min": 0, "max": 100, "step": 1}], "noise_mask": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "force_inpaint": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "bbox_threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "bbox_dilation": ["INT", {"default": 10, "min": -512, "max": 512, "step": 1}], "bbox_crop_factor": ["FLOAT", {"default": 3.0, "min": 1.0, "max": 10, "step": 0.1}], "sam_detection_hint": [["center-1", "horizontal-2", "vertical-2", "rect-4", "diamond-4", "mask-area", "mask-points", "mask-point-bbox", "none"]], "sam_dilation": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1}], "sam_threshold": ["FLOAT", {"default": 0.93, "min": 0.0, "max": 1.0, "step": 0.01}], "sam_bbox_expansion": ["INT", {"default": 0, "min": 0, "max": 1000, "step": 1}], "sam_mask_hint_threshold": ["FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01}], "sam_mask_hint_use_negative": [["False", "Small", "Outter"]], "drop_size": ["INT", {"min": 1, "max": 16384, "step": 1, "default": 10}], "bbox_detector": ["BBOX_DETECTOR"], "wildcard": ["STRING", {"multiline": true, "dynamicPrompts": false}], "cycle": ["INT", {"default": 1, "min": 1, "max": 10, "step": 1}]}, "optional": {"sam_model_opt": ["SAM_MODEL"], "segm_detector_opt": ["SEGM_DETECTOR"], "detailer_hook": ["DETAILER_HOOK"], "inpaint_model": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "noise_mask_feather": ["INT", {"default": 20, "min": 0, "max": 100, "step": 1}], "scheduler_func_opt": ["SCHEDULER_FUNC"], "tiled_encode": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "tiled_decode": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}]}}, "input_order": {"required": ["image", "model", "clip", "vae", "guide_size", "guide_size_for", "max_size", "seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "denoise", "feather", "noise_mask", "force_inpaint", "bbox_threshold", "bbox_dilation", "bbox_crop_factor", "sam_detection_hint", "sam_dilation", "sam_threshold", "sam_bbox_expansion", "sam_mask_hint_threshold", "sam_mask_hint_use_negative", "drop_size", "bbox_detector", "wildcard", "cycle"], "optional": ["sam_model_opt", "segm_detector_opt", "detailer_hook", "inpaint_model", "noise_mask_feather", "scheduler_func_opt", "tiled_encode", "tiled_decode"]}, "output": ["IMAGE", "IMAGE", "IMAGE", "MASK", "DETAILER_PIPE", "IMAGE"], "output_is_list": [false, true, true, false, false, true], "output_name": ["image", "cropped_refined", "cropped_enhanced_alpha", "mask", "detailer_pipe", "cnet_images"], "name": "FaceDetailer", "display_name": "FaceDetailer", "description": "This node enhances details by automatically detecting specific objects in the input image using detection models (bbox, segm, sam) and regenerating the image by enlarging the detected area based on the guide size.\nAlthough this node is specialized to simplify the commonly used facial detail enhancement workflow, it can also be used for various automatic inpainting purposes depending on the detection model.", "python_module": "custom_nodes.comfyui-impact-pack", "category": "ImpactPack/Simple", "output_node": false}}